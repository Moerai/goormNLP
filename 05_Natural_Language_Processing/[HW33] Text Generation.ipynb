{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"[HW33] Text Generation.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Ms57zoghuNDp"},"source":["##**10. Text Generation**\n","1. Pretrained Model을 이용해 Text를 generation 하는 model을 구현합니다.\n","2. 실제 데이터셋을 가지고 모델을 학습해봅니다.\n","3. 다양한 decoding strategy를 이용하여 text를 생성해봅니다."]},{"cell_type":"code","metadata":{"id":"GZA8dewtuNDs","outputId":"c511c5d4-360b-47e6-de07-b8dcba353014"},"source":["!pip install transformers==4.9.2"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers==4.9.2 in /home/jiminhong/anaconda3/lib/python3.8/site-packages (4.9.2)\n","Requirement already satisfied: pyyaml>=5.1 in /home/jiminhong/anaconda3/lib/python3.8/site-packages (from transformers==4.9.2) (5.3.1)\n","Requirement already satisfied: regex!=2019.12.17 in /home/jiminhong/anaconda3/lib/python3.8/site-packages (from transformers==4.9.2) (2020.10.15)\n","Requirement already satisfied: sacremoses in /home/jiminhong/anaconda3/lib/python3.8/site-packages (from transformers==4.9.2) (0.0.43)\n","Requirement already satisfied: tqdm>=4.27 in /home/jiminhong/anaconda3/lib/python3.8/site-packages (from transformers==4.9.2) (4.49.0)\n","Requirement already satisfied: filelock in /home/jiminhong/anaconda3/lib/python3.8/site-packages (from transformers==4.9.2) (3.0.12)\n","Requirement already satisfied: numpy>=1.17 in /home/jiminhong/anaconda3/lib/python3.8/site-packages (from transformers==4.9.2) (1.19.2)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/jiminhong/anaconda3/lib/python3.8/site-packages (from transformers==4.9.2) (0.10.3)\n","Requirement already satisfied: packaging in /home/jiminhong/anaconda3/lib/python3.8/site-packages (from transformers==4.9.2) (20.4)\n","Requirement already satisfied: requests in /home/jiminhong/anaconda3/lib/python3.8/site-packages (from transformers==4.9.2) (2.24.0)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /home/jiminhong/anaconda3/lib/python3.8/site-packages (from transformers==4.9.2) (0.0.12)\n","Requirement already satisfied: click in /home/jiminhong/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers==4.9.2) (7.1.2)\n","Requirement already satisfied: six in /home/jiminhong/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers==4.9.2) (1.15.0)\n","Requirement already satisfied: joblib in /home/jiminhong/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers==4.9.2) (0.17.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /home/jiminhong/anaconda3/lib/python3.8/site-packages (from packaging->transformers==4.9.2) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /home/jiminhong/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.9.2) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/jiminhong/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.9.2) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/jiminhong/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.9.2) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /home/jiminhong/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.9.2) (2.10)\n","Requirement already satisfied: typing-extensions in /home/jiminhong/anaconda3/lib/python3.8/site-packages (from huggingface-hub==0.0.12->transformers==4.9.2) (3.7.4.3)\n"]}]},{"cell_type":"code","metadata":{"id":"KjXsPeEmuNDt"},"source":["import torch\n","from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ejK--Ti8uNDt"},"source":["import numpy as np\n","import random\n","\n","def set_seed(random_seed):\n","    torch.random.manual_seed(random_seed)\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(random_seed)\n","    random.seed(random_seed)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vHDikSuCuNDu"},"source":["set_seed(777)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M7FjE7qMuNDu","outputId":"c9af222b-b1a7-423d-924d-87d3699cf2f8"},"source":["model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n","  pad_token='<pad>', mask_token='<mask>') "],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]}]},{"cell_type":"code","metadata":{"id":"MiZH_qkGuNDv"},"source":["text = '근육이 커지기 위해서는'\n","input_ids = tokenizer.encode(text)\n","gen_ids = model.generate(torch.tensor([input_ids]),\n","                           max_length=50,repetition_penalty=1.0,\n","                           top_k=5,\n","                           temperature=1.0,                          \n","                           pad_token_id=tokenizer.pad_token_id,\n","                           eos_token_id=tokenizer.eos_token_id,\n","                           bos_token_id=tokenizer.bos_token_id)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YwyDgyC8uNDw","outputId":"4fdec251-6c01-45c4-cbf7-782aa499e94b"},"source":["generated = tokenizer.decode(gen_ids[0,:].tolist())\n","print(generated)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["근육이 커지기 위해서는 무엇보다 규칙적인 생활습관이 중요하다.\n","특히, 아침식사는 단백질과 비타민, 무기질 등 영양소가 풍부한 음식을 골고루 섭취하는 것이 좋다.\n","또한 규칙적인 운동은 근육을 강화시켜주는 효과가 있다.\n","특히, 아침식사는 단백질과 비타민\n"]}]},{"cell_type":"markdown","metadata":{"id":"6DMYgGHFuNDw"},"source":["## Likelihood-based Decoding\n","\n","* Greedy Search\n","* Beam Search"]},{"cell_type":"code","metadata":{"id":"glpWw8vxuNDx"},"source":["def greedy(logits):\n","    return torch.argmax(logits, dim=-1, keepdim=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rH_Wjo0vuNDx"},"source":["class SamplerBase:\n","    def __init__(self, model, seq_length):\n","        self.model = model\n","        self.seq_length = seq_length\n","\n","    def sample(self, inps, past):\n","        return NotImplementedError"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2jX1NiWzuNDx"},"source":["from copy import deepcopy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XACVQ6rbuNDy"},"source":["## Greedy Search Decoding"]},{"cell_type":"code","metadata":{"id":"7nc_mX7huNDy"},"source":["\n","def greedy(logits):\n","    return torch.argmax(logits, dim=-1, keepdim=True)\n","\n","class GreedySampler(SamplerBase):\n","    def __init__(self, model, seq_length, top_whatever, stochastic=False, temperature: float = 1.0):\n","        \"\"\"\n","        :param model:\n","        :param seq_length:\n","        :param stochastic: choice [top_k,top_p] if True\n","        \"\"\"\n","        super(GreedySampler, self).__init__(model, seq_length)\n","\n","        self.sampling = greedy\n","\n","    @torch.no_grad()\n","    def sample(self, inps):\n","        inps=torch.LongTensor([inps])        \n","        context = inps\n","        generated = deepcopy(inps)\n","        past = None\n","\n","        for t in range(0, self.seq_length):\n","            out = self.model(context, past_key_values=past)\n","            lm_logits,past= out[\"logits\"],out[\"past_key_values\"]\n","            \n","            lm_logits = lm_logits[:, -1]\n","            \n","            context = self.sampling(lm_logits)\n","            generated = torch.cat([generated, context], dim=-1)\n","\n","        return generated\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F6ybZxruuNDz"},"source":["## Hugging face Library"]},{"cell_type":"code","metadata":{"id":"FDWOcTGCuNDz","outputId":"0c549eee-ee3a-4d0c-f3c9-1c4994467cd5"},"source":["gen_ids = model.generate(torch.tensor([input_ids]),max_length=34)\n","\n","generated = tokenizer.decode(gen_ids[0,:].tolist())\n","print(generated)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["근육이 커지기 위해서는 무엇보다 규칙적인 생활습관이 중요하다.\n","특히, 아침식사는 단백질과 비타민, 무기질 등 영양소가 풍부한 음식을 골고루 섭취하는 것이 좋다.\n","또한 규칙적인\n"]}]},{"cell_type":"markdown","metadata":{"id":"lQbRxH1fuNDz"},"source":["## 비교해보기"]},{"cell_type":"code","metadata":{"id":"1G-2f5oxuNDz","outputId":"a8b0cc71-e927-4d9d-9f0d-a1437ce379bd"},"source":["\n","sampler=GreedySampler(model,30,1)\n","\n","sampled_ids=sampler.sample(input_ids)\n","\n","generated = tokenizer.decode(sampled_ids[0,:].tolist())\n","print(generated)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["근육이 커지기 위해서는 무엇보다 규칙적인 생활습관이 중요하다.\n","특히, 아침식사는 단백질과 비타민, 무기질 등 영양소가 풍부한 음식을 골고루 섭취하는 것이 좋다.\n","또한 규칙적인\n"]}]},{"cell_type":"markdown","metadata":{"id":"P8MJS5QcuND0"},"source":["## Beam Search Decoding"]},{"cell_type":"code","metadata":{"id":"9OI_d9rUuND0"},"source":["class BeamSampler(SamplerBase):\n","    def __init__(self, model, seq_length, beam_size: int = 3, temperature: float = 1.0):\n","        \"\"\"\n","        no version on stochastic mode\n","        :param model:\n","        :param seq_length:\n","        :param top_whatever: int as beam_size\n","        \"\"\"\n","        super(BeamSampler, self).__init__(model, seq_length)\n","        self.temperature = temperature\n","        # if not isinstance(beam_size, int):\n","        #     raise ValueError\n","        self.beam_size = beam_size\n","        self.sampling = greedy\n","\n","    def _set_start_sequence(self, inps):\n","        batch, seq_lens = inps.size()\n","        res = inps[:, None].repeat(1, self.beam_size, 1)  # [batch, beam, l]\n","        res.view(-1, seq_lens)\n","\n","        return res.view(-1, seq_lens)\n","\n","    @torch.no_grad()\n","    def sample(self, inps):\n","        inps=torch.LongTensor([inps])\n","        n_batch, seq_length = inps.size()\n","        context = self._set_start_sequence(inps)\n","        generated = deepcopy(context)\n","        past = None\n","\n","        probs = torch.zeros([n_batch * self.beam_size]).to(context.device)\n","        for t in range(0, self.seq_length):\n","            out = self.model(context, past_key_values=past)\n","            lm_logits,past= out[\"logits\"],out[\"past_key_values\"]\n","#             lm_logits, past = self.model(context, past=past)\n","            \n","            lm_logits = lm_logits[:, -1]\n","\n","            context, probs, past, generated = self.beam_sample(lm_logits, probs, t, past, generated)\n","\n","        return generated.cpu()[:, 0], probs\n","\n","    def beam_sample(self, logits, probs, time_step, past, generated):\n","\n","        if time_step == 0:\n","            logits = logits.view(-1, self.beam_size, logits.size()[-1])\n","            probs, preds = self.beam_start(logits, probs)\n","            generated = torch.cat([generated, preds], dim=-1)\n","\n","        else:\n","            logits = logits.view(-1, self.beam_size, logits.size()[-1])\n","            probs, preds, past, generated = self.beam_continue(logits, probs, past, generated)\n","\n","        return preds.view(-1, 1), probs, past, generated\n","\n","    def beam_start(self, logits, probs):\n","        logits = logits / self.temperature\n","        p, i = torch.topk(torch.log_softmax(logits, -1), self.beam_size, -1)  # [batch, beam_size]\n","        i = i.view(-1, self.beam_size, self.beam_size)[:, 0, :].contiguous().view(-1, 1)\n","        p = p.view(-1, self.beam_size, self.beam_size)[:, 0, :].contiguous().view(-1, 1)\n","\n","        probs = probs + p.view(-1)\n","\n","        return probs, i\n","\n","    def beam_continue(self, logits, probs, past, generated):\n","        bs = logits.size(0)\n","        generated = generated.view(bs, self.beam_size, -1)\n","\n","        current_p, indexes = torch.topk(torch.log_softmax(logits, -1), self.beam_size,\n","                                        -1)  # [batch_size, beam_size, beam_size]\n","        probs = probs.view(bs, -1).unsqueeze(-1) + current_p\n","        new_probs = probs.view(bs, -1)\n","\n","        probs, ni = new_probs.topk(self.beam_size, -1)\n","        sampled = indexes.view(bs, -1).gather(1, ni)  # [batch, beam]\n","        group = ni // self.beam_size\n","        ind = torch.arange(bs)[:, None], group\n","        generated = generated[ind]\n","        bs_beam = past[0][0].size(0)\n","\n","        n_head, seq_len, hidden_size = past[0][0].size()[1:]\n","\n","        past = [\n","            (k.view(bs, self.beam_size, n_head, seq_len, hidden_size)[ind].view(bs_beam, n_head, seq_len, hidden_size),\n","             v.view(bs, self.beam_size, n_head, seq_len, hidden_size)[ind].view(bs_beam, n_head, seq_len, hidden_size)) \\\n","            for k, v in past]\n","\n","        # sampled = indexes.view(bs, -1).gather(1, ni)\n","        generated = torch.cat([generated, sampled[:, :, None]], -1)\n","\n","        return probs, sampled.view(-1)[:, None], past, generated\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7IAxVMe8uND0"},"source":["## Huggingface 정답"]},{"cell_type":"code","metadata":{"id":"IsB27g1zuND0","outputId":"fffc502e-bc91-4089-a68d-718e68332016"},"source":["gen_ids = model.generate(torch.tensor([input_ids]),max_length=34,\n","                         num_beams=3,temperature=2.0)\n","generated = tokenizer.decode(gen_ids[0,:].tolist())\n","print(generated)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["근육이 커지기 위해서는 무엇보다 면역력을 높여야 한다.\n","면역력을 높여야 하는 이유다.\n","면역력을 높여야 하는 이유다.\n","면역력을 높여야 하는 이유다.\n","면역력을 높여\n"]}]},{"cell_type":"markdown","metadata":{"id":"vmODWSZouND1"},"source":["## 비교해보기"]},{"cell_type":"code","metadata":{"id":"GI34DMuquND1","outputId":"07d70155-7874-483e-de01-01e214a4a041"},"source":["sampler=BeamSampler(model,30,3,temperature=2.0)\n","\n","sampled_ids=sampler.sample(input_ids)[0]\n","\n","generated = tokenizer.decode(sampled_ids[0,:].tolist())\n","print(generated)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["근육이 커지기 위해서는 무엇보다 면역력을 높여야 한다.\n","면역력을 높여야 하는 이유다.\n","면역력을 높여야 하는 이유다.\n","면역력을 높여야 하는 이유다.\n","면역력을 높여\n"]}]},{"cell_type":"markdown","metadata":{"id":"WPY53wGtuND1"},"source":["# Stochastic-based Decoding\n","* Top-k sampling\n","\n","* Top-p sampling"]},{"cell_type":"markdown","metadata":{"id":"W3T3EuhLuND1"},"source":["## Hugging face Library"]},{"cell_type":"code","metadata":{"id":"1K7XHKYCuND1","outputId":"bb6e3396-deb8-49dc-d744-c796732563ed"},"source":["## top-k sampling\n","\n","gen_ids = model.generate(torch.tensor([input_ids]),max_length=34,\n","                         do_sample=True,top_k=5,temperature=1.0)\n","generated = tokenizer.decode(gen_ids[0,:].tolist())\n","print(generated)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["근육이 커지기 위해서는 무엇보다 영양을 공급받는 것이 중요하다.\n","영양은 바로 우리 몸을 튼튼하게 만들어준다.\n","비타민의 경우 우리 몸의 혈액 순환과 세포막의 에너지 생성을 도와주기\n"]}]},{"cell_type":"markdown","metadata":{"id":"ufub109duND2"},"source":["* top-p sampling"]},{"cell_type":"code","metadata":{"id":"LAQLpZEYuND2","outputId":"d3e47aba-fc1e-4aa5-a135-5c59f4df51f4"},"source":["## top-k sampling\n","\n","gen_ids = model.generate(torch.tensor([input_ids]),max_length=34,\n","                         do_sample=True,top_p=0.1,temperature=1.0)\n","generated = tokenizer.decode(gen_ids[0,:].tolist())\n","print(generated)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["근육이 커지기 위해서는 무엇보다 영양소가 풍부한 음식을 섭취하는 것이 중요하다.\n","특히, 비타민C가 풍부한 음식은 비타민C가 풍부한 음식을 섭취하는 것이 좋다.\n","비타민C는\n"]}]},{"cell_type":"code","metadata":{"id":"kEXgO6yMuND2"},"source":["def top_k_logits(logits, k):\n","    if k == 0:\n","        # no truncation\n","        return logits\n","    else:\n","        values, _ = torch.topk(logits, k=k)\n","        min_values = values[:, -1, None]\n","        return torch.where(\n","            logits < min_values,\n","            torch.ones_like(logits, dtype=logits.dtype) * -1e10,\n","            logits,\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ou9Nx1vuND2"},"source":["def top_p_logits(logits, p):\n","    \"\"\"Nucleus sampling\"\"\"\n","    batch = logits.size(0)\n","    sorted_logits, _ = torch.sort(logits, descending=True, dim=-1)\n","    cumulative_probs = torch.cumsum(torch.softmax(sorted_logits, dim=-1), dim=-1)\n","    a = torch.arange(0, batch).to(logits.device)\n","    b = torch.max(torch.sum(cumulative_probs <= p, dim=-1) - 1, torch.Tensor([0]).long().to(logits.device))\n","    min_values = sorted_logits[a, b].to(logits.device)\n","\n","    return torch.where(\n","        logits < min_values[:, None],\n","        torch.ones_like(logits) * -1e10,\n","        logits,\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EkJbqKYWuND2"},"source":["class StochasticSampler(SamplerBase):\n","    def __init__(self, model, seq_length, top_whatever, stochastic_func, temperature: float = 1.0):\n","        \"\"\"\n","        :param model:\n","        :param seq_length:\n","        :stochastic_func\n","        \"\"\"\n","        super(StochasticSampler, self).__init__(model, seq_length)\n","\n","        self.temperature = temperature\n","        self.top_whatever=top_whatever\n","        self.sampling = stochastic_func\n","        \n","\n","    @torch.no_grad()\n","    def sample(self, inps):\n","        inps=torch.LongTensor([inps])\n","        context = inps\n","        generated = deepcopy(inps)\n","        past = None\n","\n","        for t in range(0, self.seq_length):\n","            out = self.model(context, past_key_values=past)\n","            lm_logits,past= out[\"logits\"],out[\"past_key_values\"]            \n","            lm_logits = lm_logits / self.temperature\n","            lm_logits = lm_logits[:, -1]\n","            masked_lm_logits = self.sampling(lm_logits, self.top_whatever)\n","            context = torch.multinomial(torch.softmax(masked_lm_logits, -1), 1,generator=random_gen)\n","            generated = torch.cat([generated, context], dim=-1)\n","\n","        return generated\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T8OZGHJTuND3","outputId":"6ada5650-19b0-4b74-d3bd-6acf0facc704"},"source":["sampler=StochasticSampler(model,30,10,top_k_logits)\n","sampled_ids=sampler.sample(input_ids)\n","generated = tokenizer.decode(sampled_ids[0,:].tolist())\n","print(generated)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["근육이 커지기 위해서는 무엇보다 영양섭취가 중요하다.\n","또 영양섭취에 대한 관심이 높아지면 다이어트나 운동 등 건강관리를 위한 각종 식이요법의 개발이 필요하다.\n","영양과다\n"]}]},{"cell_type":"code","metadata":{"id":"i6VukDW0uND3","outputId":"614a2612-22c9-4a5f-d97b-6f3bcd96b43a"},"source":["sampler=StochasticSampler(model,30,0.5,top_p_logits)\n","sampled_ids=sampler.sample(input_ids)\n","generated = tokenizer.decode(sampled_ids[0,:].tolist())\n","print(generated)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["근육이 커지기 위해서는 원치 않는 곳에 무리하게 자꾸만 손이 가는 것이 가장 큰 이유다.\n","이럴 때면 엉덩이를 많이 쓸어 올리는 것보다 가볍게 하는\n"]}]},{"cell_type":"markdown","metadata":{"id":"fshMHi7duND3"},"source":["## 참고 자료"]},{"cell_type":"markdown","metadata":{"id":"ZuGbgtcYuND3"},"source":["https://huggingface.co/transformers/v2.6.0/quickstart.html#using-the-past\n","\n","https://github.com/pytorch/fairseq/blob/1f7ef9ed1e1061f8c7f88f8b94c7186834398690/fairseq/search.py#L103\n","\n","https://jeongukjae.github.io/posts/cs224n-lecture-15-natural-language-generation/"]}]}